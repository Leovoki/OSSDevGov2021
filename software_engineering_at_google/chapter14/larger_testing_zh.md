# 第十四章
## 更大的测试						
															约瑟夫·格雷夫斯撰写，汤姆·曼施莱克编辑

在前面的章节中，我们已经叙述谷歌建立了属于自己的测试文化，以及单元测试是如何成为开发人员工作流程的基本部分的。但是其他类型的测试呢?事实证明，谷歌确实使用了许多其他的比单元测试大的测试，这些测试组成了软件编程过程中重要部分，用来应对风险。为了确保它们是有价值的资产，而不是资源的消耗这成为了测试的新挑战。在这一章中，我们将讨论 “大型测试”，什么是 “大型测试”，以及保持它们有效的最佳实践。

## 什么是“更大的测试”？
  如前所述，谷歌对测试大小是有定义的。小型测试仅限于一个线程、一个进程和一台机器。大型测试没有这种的限制。但是谷歌对测试范围也有概念定义。单元测试必须比集成测试的范围小。而最大范围的测试(有时称为端到端或系统测试)通常涉及几个真正的依赖项和更少的测试替身。

大型测试包含许多小测试所没有的东西。它们不受相同的约束;因此，它们可以表现出以下特征:  

•他们可能比较慢。我们的大型测试有一个默认15分钟或1小时的超时，但是我们也有运行几个小时甚至几天的测试。  
•它们可能是非封装好的。大型测试可能与其他测试和流量共享资源。  
•他们可能是不确定的。如果一个大型测试是非封装好的，它几乎是不可能保证决定论的:也就是说其他测试或用户状态可能会干扰它。  

那么为什么要进行更大的测试呢?回想一下你怎么敲代码的。你如何保证你写的程序可以正常运行?您可能正在写和运行单元测试，但你是否发现是你自己在尝试运行这些二进制软件呢?当你与他人分享这些代码时，他们如何测试它?让他们自己尝试运行单元测试?

另外，你怎么知道在版本迭代过程种你的代码还能正常运行?假设你有一个网站用到谷歌的地图API，同时这个API有待更新。你可能并不知道测试能否和新版本兼容所以你会尝试看一下运行是否正常。

## 保真度

使用较大测试的主要原因是为了解决保真度问题。保真度是一种属性，通过它，测试可以反映在测试过程种系统的真实情况（SUT）。

设想保真度是一种根据环境的方法。正如图14-1所示，单元测试将一个测试和一小部分代码捆绑在一起作为一个可运行的单元，这确保了代码经过了测试，但不同于生产代码的运行方式。自然，生产本身就是测试中保真度最高的环境。还有一系列临时选择权。大型测试的关键是找到合适的匹配，因为提高保真度也伴随着成本的增加和(在生产环境下)失败风险的增加。

![图14-1 保真度增加的规模](https://img-blog.csdnimg.cn/20210421160629827.png)
图14-1保真度增加的规模

还可以根据测试内容对现实的逼真度来衡量测试。 许多手工的，很大的测试都被工程师忽略，是因为这些测试都看起来不真实。 从生产中复制的测试数据更加接近于现实，但是最大的挑战是如何在之启动新代码之前创建真实的测试流量。 这在人工智能（AI）中也是个问题，因此，“种子”数据经常遭受内在偏见。并且因为大部分用来单元测试的数据都是手动生成的，这些数据只包含了例子的一小部分，而且往往带别了创造数据这个人的想法。没有被测试数据覆盖到的真实场景表明了一次测试的保真度差距。

## 单元测试中的常见差距
如果较小的测试失败，则可能需要较大的测试。 遵循的小节低表示某些特定区域中的单元测试无法提供良好的风险评估位置覆盖率。紧跟其后的分段只展现了一些特定的地方，因而单元测试不能很好的提供风险缓冲覆盖。

### 不可靠的双重测试
单个单元测试通常涵盖一个类或模块。双重测试(如第13章提到的)经常被用来消除影响大的的或难以测试的依赖性。但是当这些依赖被替换时，替换物和被替换物之间可能会有分歧。

Google几乎所有的单元测试都是由编写该测试的同一位工程师编写的。当那些单元测试需要双倍时，而且是模拟的话，是由工程师来给模拟下定义和指定行为。但这位工程师通常不会写模拟，因为他们可能传达错误的信息。被测的单元与给定同伴之间的关系是一种行为契约，如果工程师错误地理解了实际行为，那么对契约的理解是无效的。

而且模拟显得陈旧。如果基于模拟的单元测试对于实际运用的作者而言不可见的话，或者实际应用改变的话， 没有任何提示可以显示该测试需要和变化同步。

请注意，正如第13章中提到的，如果团队为他们自己提供假冒的服务，这种担忧就会大大减轻。

### 配置问题
单元测试涵盖给定的二进制代码。但是，就执行方式而言，二进制文件通常不是完全自给自足的。二进制文件通常需要一定的部署配置或启动脚本。此外，真正的终端用户服务产品都有自己的配置文件或配置数据库。

如果这些文件存在问题，或者这些存储定义的状态与涉及的二进制文件之间存在兼容性问题，那么这些问题可能会导致重大的用户问题。单靠单元测试无法验证这种兼容性。另外说一句，这反而是一个让你保证配置和代码都处于版本控制中的不错理由。因为随后的配置变化可以被识别来作为bug（漏洞）的来源而不是引入外部的随机碎片并且这可以运用于大测试中。

*[单靠单元测试无法验证这种兼容性。]:   请参阅第483页和第25章的“持续交付”了解更多信息。


在谷歌，配置更改是我们主要停机的首要原因。这是我们表现不佳的一个领域，并导致了一些最令人尴尬的bug。例如，在2013年有一次谷歌的全球宕机，原因是一个糟糕的网络配置推送因为它未经测试。配置往往是用配置语言编写的，而不是生产环境的代码编写的。与二进制文件相比，它们的产品推出周期通常更快，而且可能更难被测试。所有这些都导致了失败的可能性。但至少在这种情况下(以及其他情况)，配置被包括进版本控制，然后我们可以很快的找到罪魁祸首并减轻问题的发生。

### 负载情况下的问题
在谷歌，单元测试的目的是要小而快，因为它们需要适应我们的标准测试的基础结构，而且还可以作为无摩擦开发人员工作流的一部分而多次运行。但是性能、负载和压力测试通常需要向给定的二进制文件发送大量的通信。这么大的量在普通的单元测试模型中很难进行。而且我们的访问量非常大，通常每秒有数千或数百万次查询(比如广告和实时竞价)！

### 未预料到的行为、输入和副作用
单元测试是受限于工程师的想象力的。也就是说，它们只能测试预期的行为和输入。然而，用户在产品中发现的问题大多是意料之外的(否则，它们不太可能作为问题出现在最终用户面前)。这一事实表明，需要不同的测试技术来测试未预料到的行为。
Hyrum法则在这里是一个重要的考虑因素:即使我们可以100%地测试一致性基于严格的具体的协议，有效的用户合同适用于所有可见的行为，而不仅仅是一个规定的合同。单元测试不太可能单独测试公共API中没有指定的所有可见行为。

### 突发行为与“真空效应”
单元测试被限制在它们所覆盖的范围内(特别是在广泛使用双重测试的情况下)，因此，如果行为在这个范围之外的区域发生了变化，则无法检测到它。而且，由于单元测试被设计成快速和可靠的，它们有意地消除了实际依赖关系、网络和数据的混乱。单元测试就像理论物理学中的问题:放在真空中，巧妙地隐藏在现实世界的混乱之中，这对速度和可靠性很有好处，但却忽略了某些缺陷。

## 为什么不进行更大的测试呢？
在前面的章节中，我们讨论了开发人员友好测试的许多属性。
特别地，它需要如下：

可靠的
它一定不能剥落，并且必须提供有用的通过/失败信号。

快速地:
它需要足够快以不打扰开发人员的工作流程。

可扩展:
Google需要能够有效地运行所有这些有用的受影响的测试，以进行预sub-麻省理工学院和提交后。好的单元测试具有所有这些特性。较大的测试通常会违反所有这些条件约束。例如，较大的测试通常比较脆弱，因为它们使用更多的红外线结构要比小型单元测试好。它们通常也慢得多，两者都需要设置以及跑步。而且由于资源和时间的原因，他们很难扩展要求，但通常还因为它们不是孤立的—这些测试可能会发生冲突彼此之间。

另外，较大的测试提出了另外两个挑战。首先，有一个挑战所有权。单元测试显然由拥有该测试的工程师（和团队）拥有单元。较大的测试跨多个单元，因此可以跨多个所有者。这提出了长期所有权挑战：谁负责维护测试当测试中断时，谁负责诊断问题？没有明确所有权，考验腐烂。

大型测试的第二个挑战是标准化（或缺乏标准化）之一。
与单元测试不同，大型测试的基础设施缺乏标准化编写，运行和调试它们的结构和过程。的方法大型测试是系统架构决定的产物，因此引入了var-要求的测试类型。例如，我们构建和运行A-B差异的方式Google Ads中的回归测试与此类测试的方式完全不同在搜索后端中构建并运行，这与云端硬盘有所不同。他们使用不同的功能强大的平台，不同的语言，不同的基础架构，不同的库，以及竞争性测试框架。

缺乏标准化会产生重大影响。 因为较大的测试有有许多种运行方式，在大规模更改中通常会跳过它们。 （看第22章。基础结构没有运行这些测试的标准方法，并且要求执行LSC的人员了解每个测试的本地详细信息团队规模不大。 由于大型测试的实施因团队而异，实际测试这些团队之间的集成的测试需要统一的不兼容可行的基础架构。也因为缺少相应的标准化流程，我们不能教对Nooglers(新谷歌人)或更有经验的工程师采取单一的方法，这既使这种情况持续下去，也导致人们对此类测试的动机缺乏理解。

## 在谷歌更大的测试
当我们之前讨论谷歌的测试历史时(见第11章)，我们提到了谷歌网络服务 (GWS)是如何在2003年强制进行自动化测试的，以及这是如何成为一个分水岭的。然而，在此之前，我们实际上已经使用了自动化测试，但常见的做法是使用自动化的大型测试。例如，AdWords在2001年创建了一个端到端测试，以验证产品的实际情况。类似地，2002年，Search为它的索引代码编写了一个类似的“回归测试”，而AdSense(它甚至还没有公开发布)在AdWord上创建了它的变体。

其他“更大”的测试模式大约也存在于2002年。谷歌搜索前端严重依赖端到端测试场景的手动qa -手动版本。和Gmail获得了它的“本地演示”环境版本——一个脚本，用来在本地创建一个端到端Gmail环境，并生成一些测试用户和邮件数据，用于本地手动测试。

当C/J构建(我们的第一个持续构建框架)发布时，它并没有区分单元测试和其他测试，但是有两个关键的开发导致了分裂。
首先，谷歌专注于单元测试，因为我们希望鼓励测试金字塔，并确保绝大多数的书面测试都是单元测试。
第二，当TAP取代C/J Build作为我们正式的持续构建系统时，它只能对满足TAP合格性要求的测试这样做:可在单个更改下构建的密封测试，该更改可以在最大时间限制内运行在我们的构建/测试集群上。
虽然大多数单元测试满足这一要求，但大型测试大多不满足这一要求。
然而，这并没有阻止对其他类型的测试的需要，它们继续填补覆盖范围的空白。
C/J Build甚至为了处理这类测试而存在了好几年，直到更新的系统取代它。

### 更大的测试和更多的时间
在本书中，我们探讨了时间对软件工程师的影响因为谷歌开发的软件已经运行了20多年。是如何受时间维度影响较大的测试?我们知道某些活动会代码的预期寿命越长，对各种形式的测试就越有意义在所有级别上都有意义的活动，但是测试类型是适当的在代码的预期生命周期内。

正如我们之前指出的，单元测试开始对具有预期寿命数小时以上的软件是具有意义的。在分钟级别上，手动测试是非常普遍的。往往STU在本地测试。但本地的演示可能是生产，特别是一次性脚本、演示或实验。在较长的寿命期间，手工测试将继续存在，但SUT通常会出现分歧，因为生产实例通常是云托管的，而不是本地托管的。

其余的大型测试都为长期存在的软件提供了价值，但是随着时间的增加，主要的关注点变成了此类测试的可维护性。

顺便说一下，这种时间影响可能是开发“冰淇淋甜筒”测试反模式的原因之一，如第11章所述，以及这里的图14-2所表示的。
![图14-2](https://img-blog.csdnimg.cn/20210425103209828.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjgyMzAxOQ==,size_16,color_FFFFFF,t_70)
图14-2

  
  当开发开始于手动测试时(当工程师认为代码只会持续几分钟)，这些手动测试就会累积起来，并主导整个测试组合。例如，它是相当典型的入侵一个脚本或应用程序，并通过运行它来测试它，然后继续添加功能，但继续通过手动运行它来测试它。这个原型最终会实现功能，并与他人共享，但实际上没有针对它的自动化测试。

糟糕的是，如果代码很难进行单元测试(因为它最初的实现方式)，那么唯一可以编写的自动化测试就是端到端测试，而我们在几天内就无意中创建了“遗留代码”。

在开发的头几天内通过构建单元测试向测试金字塔过渡，然后通过引入自动化集成测试和从手动的端到端测试转移到测试金字塔，这对于长期健康是至关重要的。我们成功得将单元测试作为一次请求提交了，但是覆盖单元测试和手动测试之间的差距对于长期健康运行是必要的。

### 谷歌规模的更大测试
在更大的软件规模中，似乎更大的测试更有必要也更合适，但即便如此，编写、运行、维护和调试这些测试的复杂性也会随着规模的增长而增加，甚至比单元测试更复杂。

微服务组成的一个系统或单独的服务器,公司的模式及互连附带应承担的看起来像一个图:让图中的节点数量是我们的n .每次一个新节点添加到这张图,有一个乘法效应的数量不同的执行路径。

图14-3描绘了一个想象中的SUT:这个系统由一个有用户的社交网络、一个社交图、一串帖子和一些广告组成。广告是由广告商创造的，并在社交流的背景下服务。这个SUT单独由两组用户、两个ui、三个数据库、一个索引管道和六个服务器组成。
图中枚举了14条边。测试所有的端到端可能性已经很困难了。想象一下，如果我们向这个组合中添加更多的服务、管道和数据库:照片和图像、机器学习照片分析等等?

![图14-3](https://img-blog.csdnimg.cn/20210425111945182.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjgyMzAxOQ==,size_16,color_FFFFFF,t_70)图14-3 一个相当小的SUT的例子:一个带有广告的社交网络

以端到端方式进行测试的不同场景的速率可以呈指数级增长或组合增长，这取决于被测试系统的结构，而且这种增长不具有伸缩性。因此，随着系统的增长，我们必须找到可选择的更大的测试策略来保持可管理。

然而，由于为实现这一比例尺而作出的必要决定，这种检验的价值也有所增加。
这是保真度的影响:
当我们迈向大N层软件,如果服务双打低保真(1 -ε),错误的机会把它放在一起时指数n .再看看这个例子SUT,如果我们将用户服务器和广告服务器替换为双打和混双低保真(例如,10%准确),
出现bug的可能性为99%(1(0.1 0.1))。这还只是两个低保真度。

因此，以在此规模上工作良好但保持合理高保真度的方式实现更大的测试变得至关重要。

![图14-4](https://img-blog.csdnimg.cn/20210425112212624.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjgyMzAxOQ==,size_16,color_FFFFFF,t_70)
图14-4 链式测试

## 更大测试的结构

尽管大型测试不受小型测试约束的约束，并且可以由任何东西组成，但大多数大型测试都表现出常见的模式。大型测试通常包含以下阶段的工作流:  

•获得一个被测系统  
•播种必要的试验数据  
•使用被测系统执行操作  
•验证行为  

## 被测系统
大型测试的一个关键组成部分就是前述的SUT（见图14-5）。 典型的单元测试将注意力集中在一个类或模块上。 而且，测试代码与被测试的代码在相同的进程（或Java情况下为Java虚拟机[JVM]）中运行。 对于较大的测试，SUT通常非常不同。 一个或多个带有测试代码的单独进程经常（但不总是）在其自己的进程中。
*图14-5.被测系统示例*
在Google，我们使用许多不同形式的SUT，SUT的范围是大型测试本身范围的主要驱动力之一（SUT越大，测试越大）。 可以根据两个主要因素来判断每种SUT形式：
*气密性*
这是SUT与正在使用的产品以及与所测试以外的其他组件之间的交互作用的隔离。 具有高度气密性的SUT暴露于并发源和基础架构脆弱性的可能性最小。
*保真度*
SUT反映测试中的生产系统的准确性。 具有高保真度的SUT将包含类似于生产版本的二进制形式（依赖于相似的配置，使用相似的基础结构并且具有相似的整体拓扑）。
通常来说这两个因素会有矛盾。
以下是部分SUT的实例：
*单进程SUT*
整个被测系统都打包为一个二进制文件（即使在生产中它们是多个单独的二进制文件）。 此外，可以将测试代码打包到与SUT相同的二进制文件中。 如果所有内容都是单线程的，则这种测试-SUT组合可能是“小型”测试，但对生产拓扑和配置的可信度最低。
*单机SUT*
被测系统由一个或多个单独的二进制文件（与生产系统相同）组成，并且测试是其自己的二进制文件。 但是一切都在一台机器上运行。 这用于“中等”测试。 理想情况下，我们在本地运行这些二进制文件时使用每个二进制文件的生产启动配置，以提高保真度。
*多机SUT*
被测系统分布在多台机器上（非常像生产云部署）。 与单机SUT相比，它的保真度甚至更高，但是它的使用使测试变得“大”，并且这种组合容易受到网络和机器脆弱性的影响。
*共享环境（暂存和生产）*
该测试仅使用共享环境，而不是运行独立的SUT。这样做成本最低，因为这些共享环境通常已经存在，但是该测试可能与其他同时使用发生冲突，因此必须等待将代码推送到这些环境中。 。 生产还增加了最终用户影响的风险。
*混合情况*
一些SUT表示混合：可能可以运行某些SUT，但可以使其与共享环境交互。 通常，要测试的事物是显式运行的，但其后端是共享的。 对于一家像Google这样规模庞大的公司来说，实际上不可能运行所有Google互连服务的多个副本，因此需要某种混合。

### 密封式SUT的好处
大型测试中的SUT可能是不可靠和周转时间长的主要来源。例如，生产测试使用实际的生产系统部署。 如前所述，这是流行的，因为环境没有额外的开销成本，但是在代码到达该环境之前无法运行生产测试，这意味着这些测试本身无法阻止代码向该环境的发布，也即SUT为时已晚。
最常见的第一种选择是创建一个巨大的共享登台环境并在其中运行测试。 这通常是在某些发行促进过程中完成的，但它再次将测试执行限制为仅在代码可用时执行。作为替代方案，一些团队将允许工程师在临时环境中“保留”时间，并使用该时间窗口来部署待处理的代码并运行测试，但这并不能随着越来越多的工程师或越来越多的服务而扩展 ，因为环境，其用户数量以及用户冲突的可能性都在迅速增长。
下一步是支持云隔离的或机器密封的SUT。这样的环境通过避免冲突和代码发布的保留要求来改善情况。
***
## 案例研究：在生产和Webdriver Torso中进行测试的风险
我们提到在生产中进行测试可能会带来风险。生产中的测试导致的一个幽默事件被称为Webdriver Torso事件。我们需要一种方法来验证YouTube产品中的视频渲染是否正常地创建了自动脚本来生成测试视频，上传它们并验证上传的质量 这是在Google拥有的YouTube频道Webdriver Torso中完成的。 但是这个频道和大多数视频都是公开的。
随后，该频道在《连线》上的一篇文章中进行了宣传，导致该频道在媒体中广泛传播，并为解决这个谜团做出了后续努力。 最后，博主将所有内容都归还给Google。最终，我们通过玩一些有趣的游戏而变得干净，包括Rickroll和Easter Egg，因此一切工作都很好。但是我们确实需要考虑最终用户发现我们生产中包含的任何测试数据并为此做好准备的可能性。
***
### 在边界减小SUT大小
有一些特别不友好的测试边界可以避免。涉及前端和后端的测试十分痛苦，因为众所周知，用户界面（UI）测试不可靠且成本很高。
* UI经常变化外观，这使UI测试变难，但实际上并没有影响基础行为。
* UI通常具有难以测试的异步行为。 

尽管对服务的UI进行端到端测试一直到后端都很有用，但是这些测试对UI和后端都有成倍的维护成本。 相反，如果后端提供了公共API，则通常更容易在UI / API边界将测试分为连接的测试，并使用公共API驱动端到端测试。 无论UI是浏览器，命令行界面（CLI），桌面应用程序还是移动应用程序，这都是正确的。
第三方依赖项是另一个特殊的边界。 第三方系统可能没有用于测试的公共共享环境，在某些情况下，将流量发送给第三方会产生一定的成本。 因此，不建议让自动化测试使用真正的第三方API，并且这种依赖关系是拆分测试的重要缝隙。
为了解决此大小问题，我们通过用内存数据库替换其数据库并删除了我们实际关心的SUT范围之外的其中一台服务器，从而使该SUT变得更小，如图14-6所示。 该SUT更有可能安装在一台机器上。
*图14-6.SUT裁剪版*
关键在于确定保真度与成本/可靠性之间的权衡，并确定合理的界限。 如果我们可以运行少量的二进制文件并进行测试，然后将其全部打包到执行常规编译，链接和单元测试执行的同一台计算机中，那么对于我们的工程师而言，我们将拥有最简单，最稳定的“集成”测试。
### 记录/重播的代理
在上一章中，我们讨论了测试加倍和方法，这些方法可用于将被测类与其难以测试的依赖项分离开来。我们还可以通过使用具有等效API的模拟，存根或伪造服务器或进程来使整个服务器和进程加倍。但是，不能保证所使用的测试倍数实际上符合它要替换的真实物品的协议。
处理SUT的依存于附属服务的一种方法是使用双重测试，但人们如何知道双重反映依存关系的实际行为呢？ 在Google之外，一种日益增长的方法是使用一个框架来进行消费者驱动的合同测试。这些是为客户和服务提供者定义合同的测试，并且该合同可以推动自动化测试。也就是说，客户端定义了服务的模拟，也即对于这些输入参数，我得到特定的输出。然后，真实服务在真实测试中使用该输入/输出对，以确保在给定这些输入的情况下产生该输出。消费者驱动的合同测试的两个公共工具是契约合同测试和Spring Cloud合同。Google严重依赖协议缓冲区，这意味着我们不在内部使用这些缓冲区。
在Google，我们做了一些与众不同的事情。最受欢迎的方法（有一个公共API）是使用较大的测试来生成较小的测试，即在运行较大的测试时记录到这些外部服务的流量，并在运行较小的测试时重放这些流量。较大的测试或“记录模式”测试在提交后连续运行，但是其主要目的是生成这些流量日志（必须通过测试才能生成日志）。在开发和预提交测试期间使用较小的或“重播模式”测试。
记录/重放的工作方式有趣的方面之一在于，由于不确定性，必须通过匹配器匹配请求以确定要重放的响应。这使得它们与存根和模拟非常相似，因为参数匹配用于确定结果行为。
在新的测试或客户端行为发生显著变化的测试中会发生什么情况？在这些情况下，请求可能不再与记录的流量文件中的内容匹配，因此测试无法在重播模式下通过。在这种情况下，工程师必须以“记录”模式运行测试以生成新的流量，因此使“运行”记录测试简易、快速和稳定是十分重要的。
## 测试数据
一个测试需要数据，而一个大型测试则需要两种不同的数据：
*种子数据*
预初始化到被测系统中的数据，反映了测试开始时SUT的状态。
*测试轨迹*
在测试执行期间由测试本身发送到被测系统的数据。
由于存在单独且更大的SUT的概念，因此，播种SUT状态的工作通常比在单元测试中完成的设置工作要复杂几个数量级。
例如：
*域数据*
一些数据库包含预先填充到表中并用作环境配置的数据。如果未提供域数据，则使用此类数据库的实际服务二进制文件可能会在启动时失败。
*现实的基线*
为了将SUT视为现实，可能会在启动时就质量和数量方面要求一组现实的基础数据。例如，社交网络的大型测试可能需要一个真实的社交图作为测试的基本状态：足够多的具有逼真的配置文件的测试用户以及这些用户之间必须存在足够的互连关系才能接受测试。
*播种APIs*
用来播种数据的API可能很复杂。 可能可以直接写入数据存储，但是这样做可能会绕过由执行写入操作的实际二进制文件执行的触发器和检查。
数据可以通过不同的方式生成，例如：
*手工数据*
像较小的测试一样，我们可以手动为较大的测试创建测试数据。 但是在大型SUT中为多个服务设置数据可能需要更多的工作，并且我们可能需要为大型测试创建大量数据。
*复制的数据*
我们可以复制数据，通常是从生产中复制数据。例如，我们可以通过从生产地图数据的副本开始提供基准来测试地球地图，然后测试对其所做的更改。
*样例数据*
复制数据可能会提供过多的数据，无法合理使用。采样数据可以减少数据量，从而减少测试时间并使推理更加容易。“智能采样”包括复制实现最大覆盖范围所需的最小数据的技术。
## 验证
在运行SUT并将流量发送到它之后，我们仍然必须验证行为，可以通过几种不同的方法来完成此操作：
*手工*
就像您在本地尝试二进制文件时一样，手动验证使用人工与SUT交互以确定其是否正常运行。该验证可以包括通过执行一致的测试计划中定义的操作来测试回归，也可以是探索性的，通过不同的交互路径来确定可能的新故障。
请注意，手动回归测试不能线性地扩展：系统越大，并且经过的行程越多，则需要更多的人工时间进行手动测试。
*断言*
就像单元测试一样，这些是对系统预期行为的显式检查。 例如，对于Google搜索xyzzy的集成测试，一个断言可能如下：
			assertThat(response.Contains("Colossal Cave"))
*A/B比较（差异）*
A / B测试不是定义显式的断言，而是运行SUT的两个副本，发送相同的数据并比较输出。没有明确定义预期的行为：人们必须手动检查差异以确保进行任何预期的更改。
## 大规模测试类型
现在，我们可以将这些不同的SUT，数据和断言方法结合起来，以创建不同种类的大型测试。 这样，每个测试就可以减轻哪些风险就具有不同的属性。 编写，维护和调试它需要多少工作； 以及在运行资源方面的成本。
以下是我们在Google上使用的各种大型测试的列表，它们的组成方式，服务的目的以及它们的局限性：
* 一个或多个二进制文件的功能测试
* 浏览器和设备测试
* 性能，负载和压力测试
* 部署配置测试
* 探索性测试
* A / B差异（回归）测试
* 用户验收测试（UAT）
* 探针和金丝雀分析
* 灾难恢复与混乱工程
* 用户评估


考虑到如此众多的组合，因此进行了广泛的测试，我们如何管理做什么以及何时进行？ 设计软件的一部分正在起草测试计划，而测试计划的关键部分是确定需要哪种类型的测试以及每种类型需要多少测试的战略要点。该测试策略确定了主要的风险向量以及减轻这些风险向量的必要测试方法。
在Google，我们担负着“测试工程师”的专门工程角色，而我们希望优秀的测试工程师所追求的目标之一就是能够为我们的产品制定测试策略。
## 一或多个交互二进制文件功能测试
这些类型的测试具有以下特征：
* SUT：单机密封或云部署隔离
* 数据：手工制作
* 验证：断言

到目前为止，我们已经看到，单元测试无法真正保真地测试复杂的系统，这仅仅是因为它们的打包方式与实际代码的打包方式不同。许多功能测试方案与给定的二进制文件进行交互的方式与该二进制文件内部的类的交互方式不同，并且这些功能测试需要单独的SUT，因此是规范的大型测试。
测试多个二进制文件的交互比测试单个二进制文件还要复杂的情况并不奇怪。当服务被部署为许多单独的二进制文件时，微服务环境中是一个常见的用例。在这种情况下，通过启动由所有相关二进制文件组成的SUT并通过已发布的API进行交互，功能测试可以涵盖二进制文件之间的实际交互。

## 浏览器和设备测试
测试Web UI和移动应用程序是对一个或多个交互二进制文件进行功能测试的一种特殊情况。可以对基础代码进行单元测试，但是对于最终用户而言，公共API是应用程序本身。使测试通过前端与作为第三方的应用程序进行交互可以提供额外的覆盖范围。
## 性能，负载和压力测试
这些类型的测试具有以下特征：
* SUT：云部署隔离
* 数据：来自生产的手工制作或多路复用
* 验证：差异（性能指标）


尽管可以在性能，负载和压力方面测试较小的单元，但此类测试通常需要同时向外部API发送流量。 该定义意味着此类测试是多线程测试，通常在被测二进制文件的范围内进行测试。但是，这些测试对于确保版本之间的性能不会降低以及系统可以处理预期的流量高峰至关重要。
随着负载测试规模的增长，输入数据的范围也随之增长，最终将难以生成触发负载下的错误所需的负载规模。负载和压力处理是系统的“高度紧急”特性。也就是说，这些复杂的行为属于整个系统，但不属于单个成员。因此，重要的是要使这些测试看起来尽可能地接近生产环境。每个SUT都需要与生产所需资源相似的资源，并且难以减轻生产拓扑中的噪声
消除性能测试中的噪声的一项研究领域是修改部署拓扑，即各种二进制文件如何在计算机网络中分布。运行二进制文件的计算机可能会影响性能特征；因此，如果在性能差异测试中，基本版本在快速计算机（或具有快速网络的计算机）上运行，而新版本在速度较慢的计算机上运行，则它看起来将会像是性能下降。此特征意味着最佳部署是在同一台计算机上运行两个版本。如果一台机器不能同时使用两个版本的二进制文件，则另一种方法是通过执行多次运行并消除峰和谷来进行校准。
## 部署配置测试
这些类型的测试具有以下特征：
* SUT：单机密封或云部署隔离
* 数据：无
* 验证：断言（不会崩溃）


很多时候，缺陷的来源不是代码，而是缺陷的配置：数据文件，数据库，选项定义等。 较大的测试可以测试SUT及其配置文件的集成，因为在启动给定的二进制文件期间会读取这些配置文件。这样的测试实际上是对SUT的冒烟测试，不需要太多的额外数据或验证。如果SUT成功启动，则测试通过。 如果不是，则测试失败。
## 探索性测试
这些类型的测试具有以下特征：
* SUT：生产或共享暂存
* 数据：生产或已知的测试领域
* 验证：手动


探索性测试是一种手动测试的形式，其重点不是通过重复已知的测试流程来寻找行为回归，而是通过尝试新的用户场景来寻找可疑行为。受过培训的用户/测试人员通过产品的公共API与产品进行交互，寻找通过系统的新路径，以及行为是否偏离预期或直观行为，或者是否存在安全漏洞。
探索性测试对于新系统和已发布系统都非常有用，以发现意外行为和副作用。 通过让测试人员遵循贯穿系统的不同可达路径，我们可以扩大系统覆盖范围，并在这些测试人员发现错误时捕获新的自动化功能测试。 从某种意义上讲，这有点像功能集成测试的手动“模糊测试”版本。
### 局限
手动测试不能线性扩展；也就是说，进行手动测试需要人工。探索性测试中发现的任何缺陷都应使用可以更频繁地运行的自动测试来复制。
### 漏洞
我们用于手动探索性测试的一种常见方法是bug bash。一组工程师和相关人员（经理，产品经理，测试工程师，任何熟悉产品的人员）安排了一次“会议”，但在本次会议上，每个参与人员都手动进行了产品测试。可能有一些针对特定漏洞领域和/或使用系统的出发点的已发布指南，但目标是提供足够的交互方式，以记录可疑的产品行为和彻底的错误。
## A / B差异回归测试
这些类型的测试具有以下特征：
* SUT：两个部署了云的隔离环境
* 数据：通常从生产中多路复用或采样
* 验证：A / B差异比较

单元测试涵盖了一小段代码的预期行为路径。但是，无法预测给定面向公众的产品的许多可能的故障模式。此外，正如Hyrum定律所指出的那样，实际的公共API并不是声明的一种，而是产品的所有用户可见的方面。考虑到这两个属性，A / B差异测试可能是Google进行大型测试的最常见形式，这不足为奇。从概念上讲，这种方法可以追溯到1998年。自2001年以来，我们在Google的大多数产品（从广告，搜索和地图开始）就一直基于此模型进行测试。
A / B差异测试通过将流量发送到公共API并比较新旧版本之间的响应（尤其是在迁移过程中）来进行操作。行为上的任何偏差都必须按照预期或未预期的方式进行调和（回归）。在这种情况下，SUT由两组实际二进制文件组成：一组运行在候选版本上，另一组运行在基本版本上。并且第三个二进制文件发送流量并比较结果。
当然也有其他变体。我们使用A-A测试（将系统与其自身进行比较）来识别不确定的行为，噪声和脆弱性，并帮助从A-B差异中删除那些不确定性。我们还偶尔使用ABC测试，比较最后的生产版本，基准构建和有待更改的内容。最后不仅可以看到立即更改的影响，还可以在下一个发行版本看到潜在更改的累积影响。
A / B差异测试是一种方便但可自动化的方法，用于检测已启动系统的任何异常情况。

### 局限
差异测试确实带来了一些要解决的挑战:  
*赞同*  
必须有人足够理解结果，才能知道于预期是否会有任何差异。 与典型的测试不同，其不清楚差异是好是坏（或基准版本实际上是否有效），因此在此过程中通常需要手动进行操作。  
*噪音*  
对于差异测试，将任何意外的噪声引入结果的方法都会导致对结果进行更多的人工调查。因此有必要弥补噪声，这是构建良好的差异测试的一大复杂原因。  
*覆盖范围*  
为差异测试生成足够的有用流量可能是一个具有挑战性的问题。 测试数据必须涵盖足够的场景以识别极端情况下的差异，但是手动整理此类数据非常困难。  
*设置*  
配置和维护一个SUT颇具挑战性。 一次创建两个可以使复杂度增加一倍，尤其是当它们共享相互依赖关系时。
